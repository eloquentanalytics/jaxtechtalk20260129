molto intelectuale da All right, I'm going to be talking about my talk at Jax Tech. I'm going to be talking about my talk at Jax Tech. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Okay, the title of the talk is the AI innovators dilemma. What do you do with a tool that can do anything? So, the basic idea is that there is a structural boundary or barrier that prevents certain types of large companies from successfully making some sort of transition. Inertia, you know, you can call it probably a lot of different things. I took some time to make a list of some of these. And they're in my terms what I would consider to be the reasons why. I think the four that we need to start with are the ones from the innovators dilemma. You can look that up. But there are a couple that I feel like are close to also very specific for artificial intelligence use cases that I want to talk through. And they may or may not overlap. So, one is I call it the baseline requirement scale advantage. This is very specific to AI because the idea that AI is better or worse than a human at a particular task is a moving target. You don't really know how the performance is for the AI against the human unless you are constantly measuring it. And measuring it at best means doing it. And at worst is just an overhead team contributing no value and not growing in any way. So, that means that whenever you look at how much benefit can I achieve by AI, you have to discount it. You have to discount it for the presence of those people that need the comparison that need to keep doing the task. And you're going to have to rethink how they work. Because it's a different way of working. It means giving up revenue. Because if the task is to participate in an RFP process and you decide that you want the AI to submit RFPs for you, and even if you were sure, even if you were sure, even if you were 100% that the AI could do it, you would still need to leave some of it for the humans. Because you can't be 100% sure forever. Which means you still need the way for them to work together, which requires investment. And it reduces the potential benefit. So, you're going to give up revenue that way. Because you firmly believe that the AI is better than the humans. Therefore, allowing the humans to do it is to give up revenue. It's not only costing you money, it's costing you business. And it's hard to do that. Larger firms, they're not going to feel it as much. Because the amount that they donate to the baseline of the business is the same. But it's a smaller share of their total. Making the transition is harder for... It makes the transition far harder, because they don't really feel the pain for that. But smaller and nibbler competitors, even though other kinds of pressures make it more difficult for large firms, creating a structural conflict. So, it's going to be... So, where you would see that manifesting is with the enterprise for building good enough models, and then deploying them without monitoring them. And it would just feel like not a great experience. Which is interesting, because that's kind of what it's felt like for a lot of people. There's this promise of it, and then you get involved in it, and it's just kind of like not a great experience. And it's because of that. It's because that models drift, they're hard to assess, they never do everything they need to do, and so you end up just using them at some point as good as they are, and it's just not that good. Very few times have you seen these kind of deployments happen, and it turns out that they go back. Or they at least admit that they went back. So, it's a real problem for an enterprise to get itself stuff like that. I also want to talk about, because it may be part of another one here, but it's more of a strategy to kind of start thinking about this kind of situation, is an enterprise of any size or complexity will have a number of processes that they need to go through. And because an enterprise is large and complicated, the processes that they go through are going to be large and complicated. So, when you look at a particular topic, a particular process, and you say, I want to apply AI to this process, it is generally not very likely, although it's happening better and better every day, but generally it's not very likely that AI is going to be able to do 100% of that process. And the larger, more complex the organization, the higher likelihood that AI is not going to be able to handle 100% of the process. So, if it doesn't handle 100% of a process, then that means that it can't be an AI deployment. It has to be a kind of hybrid deployment, where some parts of the process are being done by AI and some parts are being done by humans, and there needs to be some kind of a trade-off, a hand-off between them. But that's almost certainly a brand new system that you'd have to build to do that, because your existing system wouldn't have been built largely for the AIs to use, and the new system that you're building won't be built for humans to use, ostensibly. That's your target. Which means you need something in the middle that is sort of both, is already designed for agents, but also has a layer for humans. That's going to be something new. And to say that you can't do it, you know, vibe coding is made for this kind of throwaway stuff, but it's still like a dynamic to think through, right? So, you have to create this thing where they come across, and then you'll essentially hit a cap. You'll hit a diminishing return. You'll always hit diminishing returns. Even if it could hypothetically do everything, you probably wouldn't ever do that, because that process I just described of taking a process and then automating it, you know, so there's much less human involvement, that is a playbook that management consultants have used for a very long time. So, there's nothing novel there. It's very safe. It's very straightforward. It's what you would do if someone came and said, I'm going to use it to automate this workflow. You don't really care that it's only 80% of it. I mean, that's a huge benefit. You're definitely getting your bonus. So, it's fine. But there's something magic that happens when something goes from 95% automated to 100% automated that is bigger than would be implied by the 5%. If you can scale something, not infinitely fast, but fast enough compared to any other paradigm that more or less is kind of scalable at will, you build another axis of scale, then you end up in an entirely different business than the one that you started on. If a hypothetical enterprise that's in... This would be the basic function of how you end up with these companies that do a single thing. Janitors say, right? Your company has an office building. They don't want to hire. They don't want to employ janitors. So, they have a service that hires and fires janitors for them, and they hire the janitorial services. There's no difference between what we're talking about. But once you start to apply it to this AI contract... Where was I? Oh, yeah. I was talking about once you get it to 100%. At that point, you were just operating on a different orthogonal basis, but you haven't yet introduced the idea of the scale being wider because scale allows you to drop the price of something because scale has a certain economy to it. And when individual companies do this internally, they usually try to do it across divisions of varying degrees of success. And when you see you do it with something like janitorial services, where you're talking about a people business, you don't necessarily get a kind of scale. The benefit comes from less overhead. You don't have to hire and fire them. You don't have to manage them. It's just a cost you're willing to pay. But there's no real economy of scale there. There's going to be some financial economy of scale, besides that way, but for the most part. If you can scale it, on an orthogonal basis, then it's a very different thing. If you can find a way to harness the economy of scale, to differentiate the service in some way, that the scale in that particular thing, there was a lot of scale required. It would be an order of magnitude greater than if an individual company tried to do it. You see that play out in, let's say, a company that does a lot of service. It's a company that does a lot of service. And it's a company that does a lot of service. It's a company that does a lot of service. You see that play out in training large foundation models. It costs way more than any individual company would want to bear to build something like that. And so they entrepreneurially pull their capital to do that. That's an example of doing that. But you can see that in any process that happens. There's the parts that the AI can do well, and there's the parts that the humans still have to be involved. And the company itself can't automate the whole thing because they need the process. There's a reason it exists. It's needed. But as a startup, you don't. As a startup, you can pick and choose which part of the process you really want to lean into. And so you can choose the parts of the process that AI is really strong at. And you can build a company that just provides that in a way that really authentically does increase the value of you doing that at scale. And value's amorphous, right? Could be faster, better, cheaper, more. Lots of ways to define value. The one thing to caveat, though, when you start to think about how to prioritize these things, is it can't be an incremental value. Incremental value does not drive switching behaviors. And it also doesn't really drive recognition. And for a startup, switching and recognition are kind of the two things that you need in order to be a business, in order to grow, in order to achieve anything. It's very difficult. So, whatever you bring to the table, or you're planning on to bring to the table, it has to be dramatically different. Headlines different. You don't necessarily have to prove it that way, or even really build it. There's obviously a risk premium, then. But you've got to have a plausible story as to how you're going to capture it. I'm going to use some examples here based on some work that I'm doing in the recruiting and staffing space, but you can apply the same model to any real business sector that you happen to be in, and be the best place for you to look to start something. So, in the recruiting and staffing business, you generally pay it on commission when you fill a role. And the amount of time that it takes to fill a role is mostly, within a fair range, the same regardless of whether you're filling a very high-salary role or a low-salary role. And the salary is, the commission is paid based on the percent of the salary. So the lower the salary goes, the less the recruiter makes on an hourly basis. And so there's a floor, not minimum wage, but these are general numbers. If you go out in the industry and you ask that question, you'll get a consistent answer of $50,000. Below $50,000, it doesn't make sense for a... It doesn't make sense for a recruiter to handle that sale, because their effective hourly rate is not high enough. So they just won't do it. So that means that if you have never had a job, or your only positions have been with companies that are hiring for less than $50,000, then you likely never worked with a recruiter. I, for one, believe a lot in the value of recruiters. I think that what they bring to a job seeker is valuable, and that they can help bridge the gap between what they know about the company based on their contacts there, and what the candidate himself brings to the table. And avoid instances where there's just... Because there is so little communication between a company and its candidates that the recruiter is really the only one that can bridge that gap. I think it's amazingly valuable work. When I look at what recruiting does, and what recruiters do, I think there is an opportunity not to provide as good of a service as recruiters do, right? I am a firm believer that AI will never exceed humans from a cognitive path. I think they'll get faster. I think they'll get cheaper. But I don't think it'll be higher quality. I think that they are a mirror of us. And to the extent that they are a fuzzy mirror, fair. But you cannot have a clearer mirror. You can only have a perfect match. And so I think that's as good as you're going to get. It's going to be a perfect match. So, being able to then say... But, as good as they are, there are people that cannot afford their services. And if I look at where AI is now, and I look at what recruiters do now, I don't think AI is particularly close to doing the job of a human recruiter. It's a very fuzzy mirror. But I think it's probably good enough to help people that don't have any experience with recruiting. Who don't have expectations about what that kind of relationship feels like. If you have never spoken to a recruiter, you don't have a frame of reference for... ...what the service is like. So, I think that the basic function of scheduling and answering questions about the company and allowing people to explain their situation and provide feedback as to how best to position themselves to the company, is to have a frame of reference. And I think that's really important. I think that's something an AI can do. Not for every job, but I think for the kinds of jobs when you look at what an under-50,000 involves, I think it can do it for those kinds of jobs. And if we can find a slice of that recruiting process, it doesn't matter which slice, it doesn't matter which job, of that recruiting process. It doesn't matter which slice. Find a slice of that process and say, you can build a recruiting company that provides a valuable service to people with less than $50,000, with 100% of the process covered by AI. It doesn't mean you don't have recruiters, it just means that you have a fraction of the recruiters that you would have. You still need a reference, and you still need smart, intelligent humans, because they can never be better than us. So the process of zeroing in on this, that is largely a process based on understanding the capabilities and limitations of artificial intelligence. They're very good at text. They're a little less good at voice. You generally have to turn it into text, and that's lossy. They're a little less good at speech. You generally have to turn it into text, and that's lossy. They're getting better at multiple modalities, but in terms of training data, which is really a great proxy for anything you want to know when you're asking if a language model is going to be good at something, is to ask how much training data is in there. You probably want to build a service that's communicated over text. Fortunately, there's a couple of those. Pretty common. But there you go. So a large enterprise company would look at that and say, well, no, of course we can't only talk by text. What if there are people that can't text, and they What if they can't text, then we will lose them as customers. To an enterprise, that seems like a lost opportunity. To a startup, that seems like not a customer. That's not someone that we consider a target for the service. It's not that we didn't drop the opportunity. That's not a part of our target addressable market. Why you would sell to people outside of your target addressable market is completely different. You just set them aside. So we're only dealing with people that communicate over text. Fortunately, text also offers another benefit, which is that its expectation is that it's quite slow, because LLMs are quite slow. It can take a very long time to get an answer from a language model. to get an answer from a language model. The larger language models, even just to start getting anything, and that's just a straightforward call, anything more sophisticated or heavy, you're talking about multiple language models, sometimes parallel, sometimes serial. The latency of them just adds up. If that user who's sitting in front of their screen and typing with someone is expecting a response time of 20 seconds or so at most, of 20 seconds or so at most, and there's probably some data on that, that would be a good graphic for the slide. That chart says how long they'll wait for a chat versus a text or an email. versus a text or an email. You'd say, well, text and email, probably do both of those, both text-based. You just have a lot more time with the text. If somebody doesn't write back for five minutes, you don't think anything of it. If somebody doesn't write back email in an hour, you don't think anything of it. It gives you so much more time for the LLM to do it An enterprise would look for more. More than that, they would say, well, why don't we do WhatsApp? Texting and WhatsApp is the same. It's not. Expectations on WhatsApp are higher. We need time for the language models to figure out what to do. And time for the human to step in to fix it if there's something wrong. It's critical. So we built our service that exchanges text-based communications with a significant time delay. Then we build an actually fairly basic agent on top of that. This kind of a customer service bot is not new. We're going to be making some tweaks to it. But it largely functions in a similar way. The magic is in the state machines that drive the communication. The magic is in the state machines that drive everything. The process that you built out. It's not in the chat bot functionality. That's not the part that really makes as much of a difference. But you have this thing. And then you start to assess the degree to which you can actually defend this niche. Because if the AI can handle 100% of it and the expectations are that you're going to exchange a couple of text messages. You're going to give you a couple of ideas. You're going to pick one. You're going to talk a little about it. You're going to schedule an interview. You're talking about 100, 150 texts over the course of a journey. Not a tremendous quantity for any given person. But you're going to assess the degree to which you can actually defend this niche. You're going to pick one. You're going to talk a little about it. You're going to schedule an interview. You're going to pick one. You're going to schedule an interview. You're going to pick one. You're going to pick one. All right. So, yeah. So you exchange some text talking about it. And then you're on your merry way. So that's not a huge expectation for an ai chatbot. So then you get down to, like, the cost side of it. And where you start thinking about the difference here is, you want to talk about dramatic changes. The typical price for, you know, the low end of the market. So, eight, ten percent on a $50,000 job is about $5,000. So you want to come into the market at $500 to be a dramatic enough difference. Ten, dramatic is usually pretty difficult to quantify, but 10x is a pretty good ballpark number for what significantly better is. So you come to the market at a $500 price point. And let's assume, you know, your margins are going to be lower because of that. Although I'm not sure your margin matters as much. Your margin is kind of opaque, so don't worry about your margin. You're going to be at a significantly lower price point. So, the thing that the lower price point gives you is not so much that it's cheaper, and therefore generates demand and generates scale. That's good. That's helpful. But it's not necessarily required for this. What you're really trying to dial in on is the competitive response. You go into a market where the mesh is like this. Of course you can chat with a recruiter over the phone. You're going to get some inroads from larger recruiting companies. And they're going to do one of a couple of different things. They probably won't come in like you are. Because that's a structural barrier for them, will be the margin. If their process, and again we're sort of assuming it's an enterprise, and we're not talking about like a hypothetical spin-off, which is kind of a little different. But their business is more complex than yours, by definition. They won't want to substantially change parts of their business that they don't consider to be threatened by you. So, that will hem them in in the number of choices they can make. So, the more difficult it is for them to adjust to that, then the harder it is, then the easier it is for you to stay unperturbed by that. So, that means that it'll be hard for them to change on the cost side of things. It's somewhat cheaper, but it's very, very difficult to get 10x cheaper without substantially changing things in a way that enterprises typically don't. And so, that gives you some protection. Even if they could make substantial changes, they likely just don't enjoy the same margin freedom as you do, which means moving into that business would mean moving into lower margin business. And in general, that's shied away from. The profitability of companies on a percentage basis is almost universally seen as how you do valuation. And even if you have more top-line revenue, you can have more top-line profit. I'm sorry, if you have top-line revenue and profit, you still are faced with that problem that you look weaker on a percentage basis. So, they're going to avoid doing that. So, you want to make sure that whatever it is you're building is actually somewhat difficult to do because the other lever that they can hold that scale gives an advantage of is they can offer it at a loss, as a loss leader. So, what that might look like for a recruiting company is that, we'll fill your roles at 50,000, below 50,000, if you give us all your roles above 50,000. And then that's somehow a different experience. But that'll be difficult for them to pull off because if it actually requires a significant amount of investment to build what you're building, and like we talked about before, the specific value to the individual company making that choice is low, then it just makes them that much less likely to do it. So, you won't see them sort of comment the same price point in order to cut you under that. And you want to avoid, if at all possible, them offering a discounted version of the service that does compete with yours as a part of a loan. That won't... That doesn't just remove the opportunity at the price point, but it does shrink the possible part of the investable market because there's a significant number of people that make less than 50,000 who work for companies with lots of other people that make more than 50,000. And the higher that ratio is, the more above $50,000 roles you have compared to $50,000 roles, the more that opportunity would shift to the incumbent provider providing a discounted service at that level. Unlikely to do that if there's 90% of people making less than 50,000 because you've been benefiting from one of these expenses than others. So it just doesn't work out that way. I don't know what the magic number is, but the functional version of how these two things are related has got to be there. It does have to be hard. There has to be somewhat of a barrier to entry where it's not just something like a skunk works that can be dreamed up in a lab. Thank you. So I want to go back then and talk about some of the other structural resistance with existing firms. I want to talk about one called divergent task preferences. Recruiters gravitate toward enjoyable bonus-rich work. An AI optimizes for speed and quality, but it doesn't matter how tedious it is. If you're left to choose, each party will push the tedious work onto the other and humans end up with repetitive training tasks while the AI claims creative victories. A recruiter-led organization, therefore, is structurally less efficient than an AI-led one because it adds the additional dimension of how personally enjoyable that task is to a human. And AIs do not value the same things from that. So by adding that sort of orthogonal dimension to the conversation, it can only make it less efficient than a purely AI-driven one. Or at least where the decision is made without that. You can see this play out with the way that humans who are training models are forced to work. They have no connection to the end result of what they're doing. They just have a series of tasks that are very similar, all the same strategies. Slightly vary in the way they're being asked. And they simply move through them. Even no matter how much you enjoy that kind of work, it'll get boring really quickly. But that's what the AIs need. If you're training an AI to do that, you need people to do it repeatedly over and over and over and over again. And so what ends up happening is the thing that puts it all together at the end, that's the fun bit, right? You take all the possible tasks and you figure out what to do. That ends up being the AI. So the AI doesn't align with the tasks and your overall level of enjoyment will fall. Therefore, people will avoid doing that and putting themselves in that position. The next one I want to talk about is legacy constraints and organizational inertia. Incumbents have existing markets. They have financing. They have corporate cultures. And in almost all cases, large corporate shareholders prefer incremental improvement over radical shifts. Part of the reason is that, and this is especially true for public companies, and to a lesser degree, large private companies, is that there's a lot of common ownership. And common ownership creates disincentives for disruption. Not necessarily because you're trying to protect the company, you're trying to protect the status quo of your company. Because when things are reliable and stable and just ticking 3% up every year, many, many, many, many people just got really excited at that prospect. And so a very risky move, with possibly unintended consequences, is going to be seen quite poorly amongst those groups. If there are strong labor protections that will push back against the free kind of shift of labor from one type to the other, then that will make it difficult for an enterprise to make this change. If the employees are part of the shareholder base, which is common in European countries, they will be less likely to move towards an AI base because humans will naturally protect them. The higher the salary level of the individuals, the more likely it is that whatever they're doing can't be done by AI. So, shifting from one to the other, the higher the salary level of the individuals, the more likely it is that whatever they're doing can't be done by AI. Whatever they're doing can't be done by AI. So, shifting from one to the other then involves slowing it down, and they'll have the ability to veto a change like that, which just slows down the ability to react. Shocks have a way of overcoming that, but they're also... So, it's not that it... Shocks can change that, but it's not something you want to plan. You can't really plan for, nor is it something you should want. It's just to observe that it's there. Another factor to talk about is the reputation and regulatory headlines. If you are replacing people with algorithms, this is generally seen as bad, and that puts your organization into a certain bind in not being able to talk about the thing that you want to do is show that you're being a good corporate steward of the organization's money. Every large company is constantly being asked questions by their shareholders. How are you trying to cut costs? How are you trying to bring more value out of the business? How are you trying to do more with the investment they've made? And that pressure is constant, constant, constant, constant. Anything that's seen as a headwind to that is to be avoided, and one headwind to that is bad for us. And so if you want to show the organization that you're being a good steward with their money... Oh, no, no, you're okay. No, you're fine. ... I didn't even know they were real. I approve. I approve.
